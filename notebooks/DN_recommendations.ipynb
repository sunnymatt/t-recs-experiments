{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# try running simulation \n",
    "import trecs\n",
    "from trecs.models import ContentFiltering, PopularityRecommender\n",
    "from trecs.components import Users, Items\n",
    "from trecs.metrics import HomogeneityMeasurement, JaccardSimilarity\n",
    "#from trecs.utils import normalize_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 100\n",
    "k_factors = 20 #k factors = 20 in Chaney et al., 2018\n",
    "n_items = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# generate user vector\n",
    "generator = np.random.default_rng()\n",
    "#user_params = np.random.dirichlet(np.ones(20), size=10) * 10\n",
    "#item_params = np.random.dirichlet(np.ones(20) * 100, size=10) * 0.1\n",
    "user_params = np.random.dirichlet(np.ones(k_factors)) * 10 #mu_rho = 10*~mu_rho from Chaney\n",
    "item_params = np.random.dirichlet(np.ones(k_factors) * 100) * 0.1 #mu_alpha = 0.1*~mu_alpha from Chaney\n",
    "# do conversion from paper to fiure out the utility percentage visible to users\n",
    "mu_n = 0.98\n",
    "sigma = 1e-5\n",
    "alpha = ((1-mu_n) / (sigma**2) - (1/mu_n)) * mu_n**2\n",
    "beta = alpha * (1/mu_n - 1)\n",
    "# each element in users is the users vector in one simulation\n",
    "#users = []\n",
    "#items = []\n",
    "#true_utilities = []\n",
    "#known_util_perc = []\n",
    "\n",
    "#for sim_index in range(user_params.shape[0]):\n",
    "#users.append(np.random.dirichlet(user_params[:], size=n_users)) # 100 users\n",
    "#items.append(np.random.dirichlet(item_params[:], size=n_items)) # 200 items\n",
    "#true_utilities.append(users[-1] @ items[-1].T)\n",
    "#known_util_perc.append(np.random.beta(alpha, beta, size=(n_users, n_items)))\n",
    "\n",
    "users=np.random.dirichlet(user_params[:], size=n_users) # 100 users\n",
    "items=np.random.dirichlet(item_params[:], size=n_items) # 200 items\n",
    "true_utilities=users[-1] @ items[-1].T\n",
    "known_util_perc=np.random.beta(alpha, beta, size=(n_users, n_items))\n",
    "    \n",
    "# print shape\n",
    "print(users.shape) # we should see 100 users with 20 attributes\n",
    "print(items.shape) # we should see 1000 items with 20 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_util_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically just recommends items based on the estimates of user preferences!\n",
    "# this will form the basis of our \"ideal\" recommender\n",
    "class IdealRecommender(ContentFiltering):\n",
    "    def _update_user_profiles(self, interactions):\n",
    "        # do not change users_hat! \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 254.93it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 6 decimals\n\n(shapes (100, 200), (100, 100, 200) mismatch)\n x: array([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],...\n y: PredictedScores([[[1.000000e+00, 1.000000e+00, 1.000000e+00, ...,\n                   1.000000e+00, 1.000000e+00, 1.000000e+00],\n                  [9.164266e+00, 1.212100e+00, 1.555044e-07, ...,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f73e020662a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mutility_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_utilities\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mideal_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m np.testing.assert_array_almost_equal(np.ones(ideal_rec.predicted_scores.shape), utility_ratio / \n\u001b[0;32m---> 27\u001b[0;31m                                       utility_ratio[:][:, np.newaxis])\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# # normal cf model for comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 6 decimals\n\n(shapes (100, 200), (100, 100, 200) mismatch)\n x: array([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],...\n y: PredictedScores([[[1.000000e+00, 1.000000e+00, 1.000000e+00, ...,\n                   1.000000e+00, 1.000000e+00, 1.000000e+00],\n                  [9.164266e+00, 1.212100e+00, 1.555044e-07, ...,..."
     ]
    }
   ],
   "source": [
    "ideal_recs = [] # store models\n",
    "cfs = []\n",
    "#pops = []\n",
    "#randoms = []\n",
    "\n",
    "#for i in range(10):\n",
    "true_user_representation = users # underlying true preferences\n",
    "true_scores = true_utilities\n",
    "noisy_scores = known_util_perc * true_utilities\n",
    "\n",
    "# generate random pairs for evaluating jaccard similarity\n",
    "pairs = [np.random.choice(100, 2, replace=False) for _ in range(500)]\n",
    "\n",
    "u = Users(actual_user_scores = noisy_scores, size=(n_users, n_factors), num_users=n_users) # each user interacts with items based on their (noisy) knowledge of their own scores\n",
    "# recommender has the ideal item representation and ideal user representation\n",
    "#ideal_rec = IdealRecommender(item_representation=items.T, user_representation=true_user_representation)\n",
    "#ideal_rec.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "#ideal_rec.run(timesteps=1000, train_between_steps=False)\n",
    "#ideal_recs.append(ideal_rec)\n",
    "\n",
    "# # make sure nothing weird happened during simulation\n",
    "#np.testing.assert_array_equal(ideal_rec.users_hat, true_user_representation)\n",
    "#np.testing.assert_array_equal(ideal_rec.items_hat, items.T)\n",
    "#np.testing.assert_array_equal(u.actual_user_scores, known_util_perc * true_utilities)\n",
    "#utility_ratio = true_utilities / ideal_rec.predicted_scores\n",
    "#np.testing.assert_array_almost_equal(np.ones(ideal_rec.predicted_scores.shape), utility_ratio / \n",
    "                                      #utility_ratio[:][:, np.newaxis]) #This fails. May be a consequence of only doing one run\n",
    "\n",
    "# # normal cf model for comparison\n",
    "\n",
    "# # model only gets item attributes, doesn't know the user preferences\n",
    "# cf = ContentFiltering(item_representation=items.T, actual_user_scores=u)\n",
    "# cf.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "# cf.startup_and_train(timesteps=50)\n",
    "\n",
    "# cf.run(timesteps=950)\n",
    "# cfs.append(cf)\n",
    "\n",
    "# # popularity model\n",
    "# p = PopularityRecommender(actual_item_representation=items.T, actual_user_representation=u, num_items=200, \n",
    "#                           num_users=100)\n",
    "# p.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "# p.startup_and_train(timesteps=50)\n",
    "# p.run(timesteps=950)\n",
    "# pops.append(p)\n",
    "\n",
    "# # random recommender\n",
    "# r = RandomRecommender(item_representation=items.T, actual_user_scores=u, num_items=200, num_users=100)\n",
    "# r.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "# r.startup_and_train(timesteps=50)\n",
    "# r.run(timesteps=950)\n",
    "# randoms.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal cf model for comparison\n",
    "\n",
    "# model only gets item attributes, doesn't know the user preferences\n",
    "cf = ContentFiltering(item_representation=items.T, actual_user_scores=u)\n",
    "cf.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "cf.startup_and_train(timesteps=50)\n",
    "\n",
    "cf.run(timesteps=950)\n",
    "cfs.append(cf)\n",
    "\n",
    "# # popularity model\n",
    "# p = PopularityRecommender(actual_item_representation=items.T, actual_user_representation=u, num_items=200, \n",
    "#                           num_users=100)\n",
    "# p.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "# p.startup_and_train(timesteps=50)\n",
    "# p.run(timesteps=950)\n",
    "# pops.append(p)\n",
    "\n",
    "# # random recommender\n",
    "# r = RandomRecommender(item_representation=items.T, actual_user_scores=u, num_items=200, num_users=100)\n",
    "# r.add_metrics(HomogeneityMeasurement(), JaccardSimilarity(pairs))\n",
    "# r.startup_and_train(timesteps=50)\n",
    "# r.run(timesteps=950)\n",
    "# randoms.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictedScores([[2.10374547e-04, 1.30183492e-04, 5.01425164e+01, ...,\n",
       "                  1.60163182e-06, 1.86703677e-05, 6.43798385e-01],\n",
       "                 [1.92792840e-03, 1.57795407e-04, 7.79738263e-06, ...,\n",
       "                  1.29028304e-05, 7.70325235e-04, 7.79733551e-06],\n",
       "                 [3.22800411e-03, 1.15508303e-03, 1.90815989e+02, ...,\n",
       "                  5.65772661e-05, 4.10146749e-03, 8.86398686e-01],\n",
       "                 ...,\n",
       "                 [7.34230557e-04, 3.57940792e-04, 2.67022635e+01, ...,\n",
       "                  1.05646211e-05, 1.81160222e-03, 6.22781584e-01],\n",
       "                 [3.57068595e-03, 1.75995229e-04, 8.48052618e-07, ...,\n",
       "                  2.72557444e-05, 7.81532580e-04, 8.48052098e-07],\n",
       "                 [6.42146820e-04, 1.43641112e-03, 4.10974088e+01, ...,\n",
       "                  1.09871508e-05, 3.89063302e-03, 5.38371061e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
